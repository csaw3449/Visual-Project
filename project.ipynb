{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Function11 to build and compile a CNN model\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[1;32m     27\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update with your dataset path\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m X, y, label_map \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add channel for grayscale\u001b[39;00m\n\u001b[1;32m     30\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(data_dir, image_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataset\u001b[39m(data_dir, image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)):\n\u001b[1;32m     13\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 14\u001b[0m     label_map \u001b[38;5;241m=\u001b[39m {gesture: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, gesture \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m)}\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m gesture, idx \u001b[38;5;129;01min\u001b[39;00m label_map\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     16\u001b[0m         gesture_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, gesture)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset'"
     ]
    }
   ],
   "source": [
    "#Hand-gesture recognition v1 / Dataset generation and NN-training\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataaugmentation import augment_dataset\n",
    "from evaluation import evaluate_model\n",
    "from CNN import build_model\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset(data_dir, image_size=(64, 64)):\n",
    "    images, labels = [], []\n",
    "    label_map = {gesture: idx for idx, gesture in enumerate(os.listdir(data_dir))}\n",
    "    for gesture, idx in label_map.items():\n",
    "        gesture_dir = os.path.join(data_dir, gesture)\n",
    "        for img_name in os.listdir(gesture_dir):\n",
    "            if img_name.endswith('.png'):  # Ensure it's a PNG file\n",
    "                img_path = os.path.join(gesture_dir, img_name)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
    "                img = cv2.resize(img, image_size) / 255.0  # Resize and normalize\n",
    "                images.append(img)\n",
    "                labels.append(idx)\n",
    "    return np.array(images), np.array(labels), label_map\n",
    "\n",
    "# Load data\n",
    "data_dir = \"dataset\"  # Update with your dataset path\n",
    "X, y, label_map = load_dataset(data_dir)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)  # Add channel for grayscale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Loaded {len(X)} images, {len(X_train)} for training, {len(X_test)} for testing.\")\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load dataset\n",
    "    data_dir = \"dataset\"  # Update this path with your dataset location\n",
    "    X, y, label_map = load_dataset(data_dir)\n",
    "    print(f\"Dataset loaded with {len(X)} images.\")\n",
    "    \n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Data augmentation\n",
    "    X_train_aug, y_train_aug = augment_dataset(X_train, y_train)\n",
    "    print(f\"Dataset augmented: {len(X_train_aug)} training samples.\")\n",
    "    \n",
    "    # Build and train model\n",
    "    model = build_model(input_shape=X_train_aug.shape[1:], num_classes=len(label_map))\n",
    "    model.fit(X_train_aug, y_train_aug, epochs=10, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_model(model, X_test, y_test, label_map)\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to evaluate and visualize results\n",
    "def evaluate_model(model, X_test, y_test, label_map):\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN with augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
